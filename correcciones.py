import json
import os
import re
from typing import Optional, Dict

CORRECCIONES_FILE = "correcciones.json"

def cargar_correcciones():
    """Carga las correcciones desde el archivo JSON"""
    if not os.path.exists(CORRECCIONES_FILE):
        return {}
    try:
        with open(CORRECCIONES_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        print("‚ö†Ô∏è Error al cargar correcciones.json, creando archivo nuevo")
        return {}

def normalizar_texto_correccion(texto: str) -> str:
    """Normaliza el texto para b√∫squeda de correcciones m√°s flexible"""
    # Convertir a min√∫sculas
    texto = texto.strip().lower()
    
    # Remover caracteres especiales y emojis comunes
    texto = re.sub(r'[üî•‚úÖüí•üöòüî∞‚ö†Ô∏èü•∂]', '', texto)
    
    # Normalizar espacios m√∫ltiples
    texto = re.sub(r'\s+', ' ', texto)
    
    # Remover puntuaci√≥n al final
    texto = re.sub(r'[.,!?]+$', '', texto)
    
    return texto.strip()

def guardar_correccion(texto: str, a√±o: int):
    """Guarda una nueva correcci√≥n"""
    correcciones = cargar_correcciones()
    texto_normalizado = normalizar_texto_correccion(texto)
    correcciones[texto_normalizado] = a√±o
    
    try:
        with open(CORRECCIONES_FILE, "w", encoding="utf-8") as f:
            json.dump(correcciones, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ Correcci√≥n guardada: '{texto[:50]}...' ‚Üí {a√±o}")
    except Exception as e:
        print(f"‚ùå Error al guardar correcci√≥n: {e}")

def obtener_correccion(texto: str) -> Optional[int]:
    """
    Busca una correcci√≥n para el texto dado.
    Primero b√∫squeda exacta, luego b√∫squeda parcial.
    """
    correcciones = cargar_correcciones()
    if not correcciones:
        return None
    
    texto_normalizado = normalizar_texto_correccion(texto)
    
    # 1. B√∫squeda exacta
    if texto_normalizado in correcciones:
        return correcciones[texto_normalizado]
    
    # 2. B√∫squeda parcial - buscar si alguna correcci√≥n est√° contenida en el texto
    texto_palabras = set(texto_normalizado.split())
    mejor_coincidencia = None
    mejor_score = 0
    
    for correccion_texto, a√±o in correcciones.items():
        correccion_palabras = set(correccion_texto.split())
        
        # Calcular intersecci√≥n de palabras
        palabras_comunes = texto_palabras.intersection(correccion_palabras)
        
        # Score basado en porcentaje de palabras coincidentes
        if len(correccion_palabras) > 0:
            score = len(palabras_comunes) / len(correccion_palabras)
            
            # Requerir al menos 70% de coincidencia
            if score >= 0.7 and score > mejor_score:
                # Verificar que tenga palabras clave importantes (modelo de auto)
                palabras_clave = {'toyota', 'honda', 'nissan', 'suzuki', 'hyundai', 'civic', 'yaris', 'sentra', 'crv', 'cr-v', 'rav4', 'accent', 'swift', 'alto'}
                if palabras_clave.intersection(correccion_palabras):
                    mejor_coincidencia = a√±o
                    mejor_score = score
    
    return mejor_coincidencia

def listar_correcciones() -> Dict[str, int]:
    """Lista todas las correcciones disponibles"""
    correcciones = cargar_correcciones()
    print(f"üìù Total de correcciones: {len(correcciones)}")
    
    # Agrupar por a√±o para mejor visualizaci√≥n
    por_a√±o = {}
    for texto, a√±o in correcciones.items():
        if a√±o not in por_a√±o:
            por_a√±o[a√±o] = []
        por_a√±o[a√±o].append(texto)
    
    for a√±o in sorted(por_a√±o.keys()):
        textos = por_a√±o[a√±o]
        print(f"\nüóìÔ∏è A√±o {a√±o} ({len(textos)} correcciones):")
        for texto in sorted(textos)[:3]:  # Mostrar solo las primeras 3
            print(f"  - {texto[:60]}...")
        if len(textos) > 3:
            print(f"  ... y {len(textos) - 3} m√°s")
    
    return correcciones

def estadisticas_correcciones():
    """Muestra estad√≠sticas de las correcciones"""
    correcciones = cargar_correcciones()
    
    if not correcciones:
        print("üìä No hay correcciones guardadas")
        return
    
    # Contar por d√©cadas
    por_decada = {}
    for a√±o in correcciones.values():
        decada = (a√±o // 10) * 10
        por_decada[decada] = por_decada.get(decada, 0) + 1
    
    print("üìä Estad√≠sticas de correcciones:")
    print(f"  Total: {len(correcciones)}")
    print("  Por d√©cada:")
    for decada in sorted(por_decada.keys()):
        print(f"    {decada}s: {por_decada[decada]} correcciones")
    
    # A√±os m√°s comunes
    a√±os_comunes = {}
    for a√±o in correcciones.values():
        a√±os_comunes[a√±o] = a√±os_comunes.get(a√±o, 0) + 1
    
    print("  A√±os m√°s frecuentes:")
    for a√±o, count in sorted(a√±os_comunes.items(), key=lambda x: -x[1])[:5]:
        print(f"    {a√±o}: {count} correcciones")

def limpiar_correcciones_duplicadas():
    """Limpia correcciones duplicadas o muy similares"""
    correcciones = cargar_correcciones()
    original_count = len(correcciones)
    
    # Agrupar por a√±o y encontrar textos muy similares
    por_a√±o = {}
    for texto, a√±o in correcciones.items():
        if a√±o not in por_a√±o:
            por_a√±o[a√±o] = []
        por_a√±o[a√±o].append(texto)
    
    correcciones_limpias = {}
    
    for a√±o, textos in por_a√±o.items():
        textos_√∫nicos = []
        
        for texto in textos:
            # Verificar si es muy similar a alg√∫n texto ya guardado
            es_similar = False
            for texto_√∫nico in textos_√∫nicos:
                # Calcular similitud b√°sica
                palabras1 = set(texto.split())
                palabras2 = set(texto_√∫nico.split())
                intersection = len(palabras1.intersection(palabras2))
                union = len(palabras1.union(palabras2))
                similitud = intersection / union if union > 0 else 0
                
                if similitud > 0.8:  # 80% de similitud
                    es_similar = True
                    break
            
            if not es_similar:
                textos_√∫nicos.append(texto)
                correcciones_limpias[texto] = a√±o
    
    # Guardar correcciones limpias
    try:
        with open(CORRECCIONES_FILE, "w", encoding="utf-8") as f:
            json.dump(correcciones_limpias, f, indent=2, ensure_ascii=False)
        
        print(f"üßπ Limpieza completada:")
        print(f"  - Antes: {original_count} correcciones")
        print(f"  - Despu√©s: {len(correcciones_limpias)} correcciones")
        print(f"  - Eliminadas: {original_count - len(correcciones_limpias)} duplicadas")
        
    except Exception as e:
        print(f"‚ùå Error al limpiar correcciones: {e}")
