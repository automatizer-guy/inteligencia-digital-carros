"""
correcciones.py - Versi√≥n Inteligente con Detecci√≥n de Patrones

Este archivo reemplaza completamente el correcciones.py original,
manteniendo compatibilidad total pero a√±adiendo inteligencia de patrones.
"""

import json
import os
import re
from typing import Optional, Dict, List
from datetime import datetime

# Importar el detector inteligente
try:
    from detector_inteligente import DetectorA√±oInteligente
    DETECTOR_DISPONIBLE = True
except ImportError:
    DETECTOR_DISPONIBLE = False
    print("‚ö†Ô∏è Detector inteligente no disponible, usando sistema b√°sico")

CORRECCIONES_FILE = "correcciones.json"

# Instancia global del detector inteligente
_detector_global = None

def _get_detector():
    """Obtiene instancia del detector inteligente (singleton)"""
    global _detector_global
    if _detector_global is None and DETECTOR_DISPONIBLE:
        _detector_global = DetectorA√±oInteligente(CORRECCIONES_FILE)
    return _detector_global

def cargar_correcciones():
    """
    Carga las correcciones desde el archivo JSON
    üîÑ COMPATIBLE: Mantiene la funci√≥n original para retrocompatibilidad
    """
    if not os.path.exists(CORRECCIONES_FILE):
        return {}
    try:
        with open(CORRECCIONES_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        print("‚ö†Ô∏è Error al cargar correcciones.json, creando archivo nuevo")
        return {}

def normalizar_texto_correccion(texto: str) -> str:
    """
    Normaliza el texto para b√∫squeda de correcciones m√°s flexible
    üîÑ COMPATIBLE: Funci√≥n original mantenida
    """
    texto = texto.strip().lower()
    texto = re.sub(r'[üî•‚úÖüí•üöòüî∞‚ö†Ô∏èü•∂]', '', texto)
    texto = re.sub(r'\s+', ' ', texto)
    texto = re.sub(r'[.,!?]+$', '', texto)
    return texto.strip()

def guardar_correccion(texto: str, a√±o: int):
    """
    Guarda una nueva correcci√≥n y re-entrena el sistema inteligente
    ‚ú® MEJORADO: Ahora re-aprende patrones autom√°ticamente
    """
    detector = _get_detector()
    
    if detector:
        # Usar sistema inteligente que re-aprende autom√°ticamente
        detector.agregar_correccion_y_reaprender(texto, a√±o)
    else:
        # Fallback al sistema original
        correcciones = cargar_correcciones()
        texto_normalizado = normalizar_texto_correccion(texto)
        correcciones[texto_normalizado] = a√±o
        
        try:
            with open(CORRECCIONES_FILE, "w", encoding="utf-8") as f:
                json.dump(correcciones, f, indent=2, ensure_ascii=False)
            print(f"‚úÖ Correcci√≥n guardada: '{texto[:50]}...' ‚Üí {a√±o}")
        except Exception as e:
            print(f"‚ùå Error al guardar correcci√≥n: {e}")

def obtener_correccion(texto: str, debug: bool = False) -> Optional[int]:
    """
    üöÄ FUNCI√ìN PRINCIPAL: Busca correcci√≥n usando sistema inteligente
    
    PRIORIDAD:
    1. Coincidencias exactas
    2. Patrones aprendidos autom√°ticamente  
    3. B√∫squeda parcial mejorada
    
    Args:
        texto: Texto a analizar
        debug: Si mostrar informaci√≥n de depuraci√≥n
        
    Returns:
        A√±o detectado o None si no se encuentra
    """
    detector = _get_detector()
    
    if detector:
        # üß† USAR SISTEMA INTELIGENTE
        resultado = detector.detectar_a√±o_inteligente(texto, debug)
        
        if debug and resultado:
            print(f"üéØ Sistema inteligente detect√≥: {resultado}")
        
        return resultado
    else:
        # üìã FALLBACK: Sistema original b√°sico
        return _obtener_correccion_basico(texto, debug)

def _obtener_correccion_basico(texto: str, debug: bool = False) -> Optional[int]:
    """
    Sistema b√°sico original como fallback
    """
    correcciones = cargar_correcciones()
    if not correcciones:
        return None
    
    texto_normalizado = normalizar_texto_correccion(texto)
    
    # 1. B√∫squeda exacta
    if texto_normalizado in correcciones:
        if debug:
            print(f"‚úÖ Coincidencia exacta: {correcciones[texto_normalizado]}")
        return correcciones[texto_normalizado]
    
    # 2. B√∫squeda parcial b√°sica
    texto_palabras = set(texto_normalizado.split())
    mejor_coincidencia = None
    mejor_score = 0
    
    for correccion_texto, a√±o in correcciones.items():
        correccion_palabras = set(correccion_texto.split())
        
        if len(correccion_palabras) > 0:
            palabras_comunes = texto_palabras.intersection(correccion_palabras)
            score = len(palabras_comunes) / len(correccion_palabras)
            
            if score >= 0.7 and score > mejor_score:
                palabras_clave = {'toyota', 'honda', 'nissan', 'suzuki', 'hyundai', 
                                'civic', 'yaris', 'sentra', 'crv', 'cr-v', 'rav4', 
                                'accent', 'swift', 'alto'}
                if palabras_clave.intersection(correccion_palabras):
                    mejor_coincidencia = a√±o
                    mejor_score = score
    
    if debug and mejor_coincidencia:
        print(f"üîç B√∫squeda parcial encontr√≥: {mejor_coincidencia} (score: {mejor_score:.2f})")
    
    return mejor_coincidencia

def listar_correcciones() -> Dict[str, int]:
    """
    Lista todas las correcciones disponibles
    üîÑ COMPATIBLE: Funci√≥n original mantenida
    """
    correcciones = cargar_correcciones()
    print(f"üìù Total de correcciones: {len(correcciones)}")
    
    # Agrupar por a√±o para mejor visualizaci√≥n
    por_a√±o = {}
    for texto, a√±o in correcciones.items():
        if a√±o not in por_a√±o:
            por_a√±o[a√±o] = []
        por_a√±o[a√±o].append(texto)
    
    for a√±o in sorted(por_a√±o.keys()):
        textos = por_a√±o[a√±o]
        print(f"\nüóìÔ∏è A√±o {a√±o} ({len(textos)} correcciones):")
        for texto in sorted(textos)[:3]:  # Mostrar solo las primeras 3
            print(f"  - {texto[:60]}...")
        if len(textos) > 3:
            print(f"  ... y {len(textos) - 3} m√°s")
    
    return correcciones

def estadisticas_correcciones():
    """
    Muestra estad√≠sticas completas del sistema
    ‚ú® MEJORADO: Ahora incluye estad√≠sticas del sistema inteligente
    """
    detector = _get_detector()
    
    if detector:
        # Mostrar estad√≠sticas del sistema inteligente
        detector.estadisticas_sistema()
    else:
        # Estad√≠sticas b√°sicas originales
        correcciones = cargar_correcciones()
        
        if not correcciones:
            print("üìä No hay correcciones guardadas")
            return
        
        # Contar por d√©cadas
        por_decada = {}
        for a√±o in correcciones.values():
            decada = (a√±o // 10) * 10
            por_decada[decada] = por_decada.get(decada, 0) + 1
        
        print("üìä Estad√≠sticas de correcciones:")
        print(f"  Total: {len(correcciones)}")
        print("  Por d√©cada:")
        for decada in sorted(por_decada.keys()):
            print(f"    {decada}s: {por_decada[decada]} correcciones")
        
        # A√±os m√°s comunes
        a√±os_comunes = {}
        for a√±o in correcciones.values():
            a√±os_comunes[a√±o] = a√±os_comunes.get(a√±o, 0) + 1
        
        print("  A√±os m√°s frecuentes:")
        for a√±o, count in sorted(a√±os_comunes.items(), key=lambda x: -x[1])[:5]:
            print(f"    {a√±o}: {count} correcciones")

def limpiar_correcciones_duplicadas():
    """
    Limpia correcciones duplicadas o muy similares
    üîÑ COMPATIBLE: Funci√≥n original mantenida
    """
    correcciones = cargar_correcciones()
    original_count = len(correcciones)
    
    # Agrupar por a√±o y encontrar textos muy similares
    por_a√±o = {}
    for texto, a√±o in correcciones.items():
        if a√±o not in por_a√±o:
            por_a√±o[a√±o] = []
        por_a√±o[a√±o].append(texto)
    
    correcciones_limpias = {}
    
    for a√±o, textos in por_a√±o.items():
        textos_√∫nicos = []
        
        for texto in textos:
            # Verificar si es muy similar a alg√∫n texto ya guardado
            es_similar = False
            for texto_√∫nico in textos_√∫nicos:
                # Calcular similitud b√°sica
                palabras1 = set(texto.split())
                palabras2 = set(texto_√∫nico.split())
                intersection = len(palabras1.intersection(palabras2))
                union = len(palabras1.union(palabras2))
                similitud = intersection / union if union > 0 else 0
                
                if similitud > 0.8:  # 80% de similitud
                    es_similar = True
                    break
            
            if not es_similar:
                textos_√∫nicos.append(texto)
                correcciones_limpias[texto] = a√±o
    
    # Guardar correcciones limpias
    try:
        with open(CORRECCIONES_FILE, "w", encoding="utf-8") as f:
            json.dump(correcciones_limpias, f, indent=2, ensure_ascii=False)
        
        print(f"üßπ Limpieza completada:")
        print(f"  - Antes: {original_count} correcciones")
        print(f"  - Despu√©s: {len(correcciones_limpias)} correcciones")
        print(f"  - Eliminadas: {original_count - len(correcciones_limpias)} duplicadas")
        
        # Si hay detector inteligente, recargar y re-aprender
        detector = _get_detector()
        if detector:
            detector.cargar_y_aprender()
            print("üß† Patrones re-aprendidos con correcciones limpias")
        
    except Exception as e:
        print(f"‚ùå Error al limpiar correcciones: {e}")

def test_sistema_inteligente():
    """
    üß™ FUNCI√ìN DE TESTING: Prueba el sistema inteligente
    """
    print("üß™ PROBANDO SISTEMA INTELIGENTE DE DETECCI√ìN")
    print("="*50)
    
    casos_prueba = [
        "Toyota yaris modelo 09",
        "Honda civic modelo 03", 
        "Suzuki swift a√±o 2011",
        "Toyota yaris del 2012",
        "Honda accord 2015",
        "Nissan sentra modelo 05 activo",
        "Vendo toyota corolla modelo 08",
        "Hyundai accent modelo 14 autom√°tico"
    ]
    
    aciertos = 0
    for i, caso in enumerate(casos_prueba, 1):
        print(f"\nüì± CASO {i}: '{caso}'")
        resultado = obtener_correccion(caso, debug=True)
        
        if resultado:
            print(f"  ‚úÖ DETECTADO: {resultado}")
            aciertos += 1
        else:
            print(f"  ‚ùå No detectado")
    
    print(f"\nüìä RESULTADO: {aciertos}/{len(casos_prueba)} casos exitosos")
    print(f"üìà Tasa de √©xito: {aciertos/len(casos_prueba)*100:.1f}%")

# FUNCI√ìN PRINCIPAL PARA COMPATIBILIDAD TOTAL
def main():
    """Funci√≥n principal para testing"""
    detector = _get_detector()
    
    if detector:
        print("üöÄ Sistema inteligente cargado exitosamente")
        test_sistema_inteligente()
    else:
        print("üìã Usando sistema b√°sico (detector inteligente no disponible)")

if __name__ == "__main__":
    main()
